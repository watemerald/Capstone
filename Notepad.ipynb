{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0dcdb7fbd4f9>:11: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File video-search/vocabulary.csv does not exist: 'video-search/vocabulary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0dcdb7fbd4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video-search/vocabulary.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.07/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.07/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.07/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.07/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.07/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File video-search/vocabulary.csv does not exist: 'video-search/vocabulary.csv'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import requests\n",
    "import re\n",
    "from typing import Union, List, Optional\n",
    "import pandas\n",
    "from dataclasses import dataclass\n",
    "\n",
    "record = \"/media/watemerald/Seagate/data/yt8m/frame/train0001.tfrecord\"\n",
    "\n",
    "features = []\n",
    "for example in tf.compat.v1.python_io.tf_record_iterator(record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    features.append(tf_example)\n",
    "\n",
    "\n",
    "def expand_vid_id(short_id: Union[bytes, str]) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # If the short_id is passed as bytes, that means that is was\n",
    "    # decoded from a TFRecord directly, in which case it's a UTF-8\n",
    "    # string\n",
    "    if isinstance(short_id, bytes):\n",
    "        short_id = short_id.decode(\"UTF-8\")\n",
    "\n",
    "    url = f\"http://data.yt8m.org/2/j/i/{short_id[:2]}/{short_id}.js\"\n",
    "    val = requests.get(url)\n",
    "\n",
    "    # The return format looks like i(\"02ab\",\"tvvJFX90eh0\");\n",
    "    # with the short id on the left and full id on the right\n",
    "    match = re.match(r\"i\\(\\\"(?P<short_id>\\w{4})\\\".\\\"(?P<full_id>\\w+)\\\"\\);\", val.text)\n",
    "\n",
    "    return match.group(\"full_id\")\n",
    "\n",
    "\n",
    "vocabulary = pandas.read_csv(\"video-search/vocabulary.csv\")\n",
    "\n",
    "\n",
    "def label_id_to_name(label: int) -> str:\n",
    "    \"\"\"Converts a single label id number to its full Knowledge Graph Name\n",
    "    \"\"\"\n",
    "    return vocabulary.iloc[label][\"Name\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VideoInfo:\n",
    "    short_id: str\n",
    "    long_id: str\n",
    "    tags: List[str]\n",
    "\n",
    "\n",
    "def decode_tf_example(e: tf.train.Example) -> VideoInfo:\n",
    "    short_id = e.features.feature[\"id\"].bytes_list.value[0]\n",
    "    labels = e.features.feature[\"labels\"].int64_list.value\n",
    "\n",
    "    long_id = expand_vid_id(short_id)\n",
    "    tags = list(map(label_id_to_name, labels))\n",
    "    return VideoInfo(short_id=short_id.decode(\"UTF-8\"), long_id=long_id, tags=tags,)\n",
    "\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "\n",
    "def display_video(vid: VideoInfo) -> YouTubeVideo:\n",
    "\n",
    "    return YouTubeVideo(vid.long_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, LeakyReLU, concatenate\n",
    "from tensorflow.keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pendulum\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.kaggle.com/drn01z3/keras-baseline-on-video-features-0-7941-lb/code\n",
    "\n",
    "FOLDER = '/media/watemerald/Seagate/data/yt8m/video/'\n",
    "\n",
    "def ap_at_n(data, n: int =20):\n",
    "    predictions, actuals = data\n",
    "    total_num_positives = None\n",
    "\n",
    "    if len(predictions) != len(actuals):\n",
    "        raise ValueError(\"the shape of predictions and actuals does not match.\")\n",
    "\n",
    "    if n is not None:\n",
    "        if not isinstance(n, int) or n <= 0:\n",
    "            raise ValueError(\"n must be 'None' or a positive integer.\"\n",
    "                             \" It was '%s'.\" % n)\n",
    "\n",
    "    ap = 0.0\n",
    "\n",
    "    sortidx = np.argsort(predictions)[::-1]\n",
    "\n",
    "    if total_num_positives is None:\n",
    "        numpos = np.size(np.where(actuals > 0))\n",
    "    else:\n",
    "        numpos = total_num_positives\n",
    "\n",
    "    if numpos == 0:\n",
    "        return 0\n",
    "\n",
    "    if n is not None:\n",
    "        numpos = min(numpos, n)\n",
    "    delta_recall = 1.0 / numpos\n",
    "    poscount = 0.0\n",
    "\n",
    "    # calculate the ap\n",
    "    r = len(sortidx)\n",
    "    if n is not None:\n",
    "        r = min(r, n)\n",
    "    for i in range(r):\n",
    "        if actuals[sortidx[i]] > 0:\n",
    "            poscount += 1\n",
    "            ap += poscount / (i + 1) * delta_recall\n",
    "    return ap\n",
    "\n",
    "\n",
    "def gap(pred, actual):\n",
    "    lst = zip(list(pred), list(actual))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        all = pool.map(ap_at_n, lst)\n",
    "\n",
    "    return np.mean(all)\n",
    "\n",
    "\n",
    "def tf_itr(tp='test', batch=1024):\n",
    "    tfiles = sorted(glob.glob(os.path.join(FOLDER,  f\"{tp}*tfrecord\")))\n",
    "    print('total files in %s %d' % (tp, len(tfiles)))\n",
    "    ids, aud, rgb, lbs = [], [], [], []\n",
    "    for fn in tfiles:\n",
    "        for example in tf.compat.v1.python_io.tf_record_iterator(fn):\n",
    "            tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "            ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "            rgb.append(np.array(tf_example.features.feature['mean_rgb'].float_list.value))\n",
    "            aud.append(np.array(tf_example.features.feature['mean_audio'].float_list.value))\n",
    "\n",
    "            yss = np.array(tf_example.features.feature['labels'].int64_list.value)\n",
    "            out = np.zeros(4716).astype(np.int8)\n",
    "            for y in yss:\n",
    "                out[y] = 1\n",
    "            lbs.append(out)\n",
    "            if len(ids) >= batch:\n",
    "                yield np.array(ids), np.array(aud), np.array(rgb), np.array(lbs)\n",
    "                # yield np.array(rgb), np.array(lbs)\n",
    "                ids, aud, rgb, lbs = [], [], [], []\n",
    "\n",
    "\n",
    "def fc_block(x, n=1024, d=0.2):\n",
    "    x = Dense(n, kernel_initializer=glorot_normal())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_mod():\n",
    "    in1 = Input((128,), name='x1')\n",
    "    x1 = fc_block(in1)\n",
    "\n",
    "    in2 = Input((1024,), name='x2')\n",
    "    x2 = fc_block(in2)\n",
    "\n",
    "#     x = merge([x1, x2], mode='concat', concat_axis=1)\n",
    "#     x = tf.concat([x1, x2], 0)\n",
    "    x = concatenate([x1,x2], 1)\n",
    "    x = fc_block(x)\n",
    "    out = Dense(4716, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    model = Model([in1, in2], out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train():\n",
    "    if not os.path.exists('weights'): os.mkdir('weights')\n",
    "    batch = 10 * 1024\n",
    "    n_itr = 10\n",
    "    n_eph = 100\n",
    "\n",
    "    _, x1_val, x2_val, y_val = next(tf_itr('val'))\n",
    "\n",
    "    model = build_mod()\n",
    "    cnt = 0\n",
    "    start = pendulum.now()\n",
    "    fmt = start.format(\"Y-MM-DD hh:mm:ss\")\n",
    "    print(f\"Started at {fmt}\")\n",
    "    \n",
    "    for e in range(n_eph):\n",
    "        for d in tf_itr('train', batch):\n",
    "            _, x1_trn, x2_trn, y_trn = d\n",
    "            model.train_on_batch({'x1': x1_trn, 'x2': x2_trn}, {'output': y_trn})\n",
    "            cnt += 1\n",
    "            if cnt % n_itr == 0:\n",
    "                y_prd = model.predict({'x1': x1_val, 'x2': x2_val}, verbose=False, batch_size=100)\n",
    "                g = gap(y_prd, y_val)\n",
    "                print('val GAP %0.5f; epoch: %d; iters: %d' % (g, e, cnt))\n",
    "                now = pendulum.now()\n",
    "                fmt = now.format(\"Y-MM-DD hh:mm:ss\")\n",
    "                print(fmt)\n",
    "                model.save_weights('weights/%0.5f_%d_%d.h5' % (g, e, cnt))\n",
    "\n",
    "def conv_pred(el):\n",
    "    t = 20\n",
    "    idx = np.argsort(el)[::-1]\n",
    "    return ' '.join(['{} {:0.5f}'.format(i, el[i]) for i in idx[:t]])\n",
    "\n",
    "\n",
    "def predict():\n",
    "    model = build_mod()\n",
    "\n",
    "    wfn = sorted(glob.glob('weights/*.h5'))[-1]\n",
    "    model.load_weights(wfn)\n",
    "    print('loaded weight file: %s' % wfn)\n",
    "    idx, x1_val, x2_val, _ = next(tf_itr('test', 10*1024))\n",
    "\n",
    "    ypd = model.predict({'x1': x1_val, 'x2': x2_val}, verbose=1, batch_size=32)\n",
    "    del x1_val, x2_val\n",
    "\n",
    "    with Pool() as pool:\n",
    "        out = pool.map(conv_pred, list(ypd))\n",
    "\n",
    "    df = pd.DataFrame.from_dict({'VideoId': idx, 'LabelConfidencePairs': out})\n",
    "    df.to_csv('subm1', header=True, index=False, columns=['VideoId', 'LabelConfidencePairs'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files in val 3844\n",
      "Started at 2020-06-04 12:11:35\n",
      "total files in train 3844\n",
      "val GAP 0.53307; epoch: 0; iters: 10\n",
      "2020-06-04 12:11:58\n",
      "val GAP 0.57145; epoch: 0; iters: 20\n",
      "2020-06-04 12:12:23\n",
      "val GAP 0.53293; epoch: 0; iters: 30\n",
      "2020-06-04 12:12:49\n",
      "val GAP 0.58610; epoch: 0; iters: 40\n",
      "2020-06-04 12:13:15\n",
      "val GAP 0.64954; epoch: 0; iters: 50\n",
      "2020-06-04 12:13:42\n",
      "val GAP 0.70675; epoch: 0; iters: 60\n",
      "2020-06-04 12:14:08\n",
      "val GAP 0.73263; epoch: 0; iters: 70\n",
      "2020-06-04 12:14:34\n",
      "val GAP 0.74543; epoch: 0; iters: 80\n",
      "2020-06-04 12:15:01\n",
      "val GAP 0.75433; epoch: 0; iters: 90\n",
      "2020-06-04 12:15:27\n",
      "val GAP 0.76547; epoch: 0; iters: 100\n",
      "2020-06-04 12:15:54\n",
      "val GAP 0.76767; epoch: 0; iters: 110\n",
      "2020-06-04 12:16:21\n",
      "val GAP 0.77408; epoch: 0; iters: 120\n",
      "2020-06-04 12:16:47\n",
      "val GAP 0.78366; epoch: 0; iters: 130\n",
      "2020-06-04 12:17:14\n",
      "val GAP 0.78244; epoch: 0; iters: 140\n",
      "2020-06-04 12:17:40\n",
      "val GAP 0.78764; epoch: 0; iters: 150\n",
      "2020-06-04 12:18:07\n",
      "val GAP 0.78782; epoch: 0; iters: 160\n",
      "2020-06-04 12:18:33\n",
      "val GAP 0.79532; epoch: 0; iters: 170\n",
      "2020-06-04 12:19:00\n",
      "val GAP 0.79444; epoch: 0; iters: 180\n",
      "2020-06-04 12:19:27\n",
      "val GAP 0.79596; epoch: 0; iters: 190\n",
      "2020-06-04 12:19:54\n",
      "val GAP 0.80024; epoch: 0; iters: 200\n",
      "2020-06-04 12:20:20\n",
      "val GAP 0.80185; epoch: 0; iters: 210\n",
      "2020-06-04 12:20:48\n",
      "val GAP 0.80527; epoch: 0; iters: 220\n",
      "2020-06-04 12:21:14\n",
      "val GAP 0.80463; epoch: 0; iters: 230\n",
      "2020-06-04 12:21:41\n",
      "val GAP 0.80583; epoch: 0; iters: 240\n",
      "2020-06-04 12:22:08\n",
      "val GAP 0.80631; epoch: 0; iters: 250\n",
      "2020-06-04 12:22:35\n",
      "val GAP 0.80373; epoch: 0; iters: 260\n",
      "2020-06-04 12:23:02\n",
      "val GAP 0.80445; epoch: 0; iters: 270\n",
      "2020-06-04 12:23:28\n",
      "val GAP 0.80607; epoch: 0; iters: 280\n",
      "2020-06-04 12:23:55\n",
      "val GAP 0.81051; epoch: 0; iters: 290\n",
      "2020-06-04 12:24:22\n",
      "val GAP 0.81202; epoch: 0; iters: 300\n",
      "2020-06-04 12:24:48\n",
      "val GAP 0.81084; epoch: 0; iters: 310\n",
      "2020-06-04 12:25:16\n",
      "val GAP 0.81300; epoch: 0; iters: 320\n",
      "2020-06-04 12:25:43\n",
      "val GAP 0.81304; epoch: 0; iters: 330\n",
      "2020-06-04 12:26:09\n",
      "val GAP 0.81469; epoch: 0; iters: 340\n",
      "2020-06-04 12:26:37\n",
      "val GAP 0.81291; epoch: 0; iters: 350\n",
      "2020-06-04 12:27:04\n",
      "val GAP 0.81409; epoch: 0; iters: 360\n",
      "2020-06-04 12:27:30\n",
      "val GAP 0.81815; epoch: 0; iters: 370\n",
      "2020-06-04 12:27:57\n",
      "total files in train 3844\n",
      "val GAP 0.81600; epoch: 1; iters: 380\n",
      "2020-06-04 12:28:26\n",
      "val GAP 0.81581; epoch: 1; iters: 390\n",
      "2020-06-04 12:28:53\n",
      "val GAP 0.81785; epoch: 1; iters: 400\n",
      "2020-06-04 12:29:20\n",
      "val GAP 0.81856; epoch: 1; iters: 410\n",
      "2020-06-04 12:29:46\n",
      "val GAP 0.81925; epoch: 1; iters: 420\n",
      "2020-06-04 12:30:13\n",
      "val GAP 0.81574; epoch: 1; iters: 430\n",
      "2020-06-04 12:30:40\n",
      "val GAP 0.82056; epoch: 1; iters: 440\n",
      "2020-06-04 12:31:07\n",
      "val GAP 0.82115; epoch: 1; iters: 450\n",
      "2020-06-04 12:31:34\n",
      "val GAP 0.81918; epoch: 1; iters: 460\n",
      "2020-06-04 12:32:01\n",
      "val GAP 0.82097; epoch: 1; iters: 470\n",
      "2020-06-04 12:32:28\n",
      "val GAP 0.82130; epoch: 1; iters: 480\n",
      "2020-06-04 12:32:55\n",
      "val GAP 0.82095; epoch: 1; iters: 490\n",
      "2020-06-04 12:33:22\n",
      "val GAP 0.81969; epoch: 1; iters: 500\n",
      "2020-06-04 12:33:48\n",
      "val GAP 0.82077; epoch: 1; iters: 510\n",
      "2020-06-04 12:34:15\n",
      "val GAP 0.81915; epoch: 1; iters: 520\n",
      "2020-06-04 12:34:41\n",
      "val GAP 0.81853; epoch: 1; iters: 530\n",
      "2020-06-04 12:35:08\n",
      "val GAP 0.81963; epoch: 1; iters: 540\n",
      "2020-06-04 12:35:35\n",
      "val GAP 0.81999; epoch: 1; iters: 550\n",
      "2020-06-04 12:36:02\n",
      "val GAP 0.82161; epoch: 1; iters: 560\n",
      "2020-06-04 12:36:28\n",
      "val GAP 0.82270; epoch: 1; iters: 570\n",
      "2020-06-04 12:36:55\n",
      "val GAP 0.82297; epoch: 1; iters: 580\n",
      "2020-06-04 12:37:22\n",
      "val GAP 0.82374; epoch: 1; iters: 590\n",
      "2020-06-04 12:37:48\n",
      "val GAP 0.82387; epoch: 1; iters: 600\n",
      "2020-06-04 12:38:14\n",
      "val GAP 0.82390; epoch: 1; iters: 610\n",
      "2020-06-04 12:38:40\n",
      "val GAP 0.82633; epoch: 1; iters: 620\n",
      "2020-06-04 12:39:07\n",
      "val GAP 0.82438; epoch: 1; iters: 630\n",
      "2020-06-04 12:39:33\n",
      "val GAP 0.82171; epoch: 1; iters: 640\n",
      "2020-06-04 12:39:59\n",
      "val GAP 0.82294; epoch: 1; iters: 650\n",
      "2020-06-04 12:40:25\n",
      "val GAP 0.82594; epoch: 1; iters: 660\n",
      "2020-06-04 12:40:51\n",
      "val GAP 0.82508; epoch: 1; iters: 670\n",
      "2020-06-04 12:41:17\n",
      "val GAP 0.82479; epoch: 1; iters: 680\n",
      "2020-06-04 12:41:43\n",
      "val GAP 0.82526; epoch: 1; iters: 690\n",
      "2020-06-04 12:42:10\n",
      "val GAP 0.82249; epoch: 1; iters: 700\n",
      "2020-06-04 12:42:36\n",
      "val GAP 0.82335; epoch: 1; iters: 710\n",
      "2020-06-04 12:43:02\n",
      "val GAP 0.82380; epoch: 1; iters: 720\n",
      "2020-06-04 12:43:28\n",
      "val GAP 0.82252; epoch: 1; iters: 730\n",
      "2020-06-04 12:43:55\n",
      "val GAP 0.82337; epoch: 1; iters: 740\n",
      "2020-06-04 12:44:21\n",
      "val GAP 0.82500; epoch: 1; iters: 750\n",
      "2020-06-04 12:44:47\n",
      "total files in train 3844\n",
      "val GAP 0.82515; epoch: 2; iters: 760\n",
      "2020-06-04 12:45:15\n",
      "val GAP 0.82449; epoch: 2; iters: 770\n",
      "2020-06-04 12:45:41\n",
      "val GAP 0.82458; epoch: 2; iters: 780\n",
      "2020-06-04 12:46:08\n",
      "val GAP 0.82559; epoch: 2; iters: 790\n",
      "2020-06-04 12:46:34\n",
      "val GAP 0.82525; epoch: 2; iters: 800\n",
      "2020-06-04 12:47:00\n",
      "val GAP 0.82470; epoch: 2; iters: 810\n",
      "2020-06-04 12:47:27\n",
      "val GAP 0.82679; epoch: 2; iters: 820\n",
      "2020-06-04 12:47:53\n",
      "val GAP 0.82698; epoch: 2; iters: 830\n",
      "2020-06-04 12:48:19\n",
      "val GAP 0.82834; epoch: 2; iters: 840\n",
      "2020-06-04 12:48:45\n",
      "val GAP 0.82938; epoch: 2; iters: 850\n",
      "2020-06-04 12:49:12\n",
      "val GAP 0.82769; epoch: 2; iters: 860\n",
      "2020-06-04 12:49:38\n",
      "val GAP 0.82732; epoch: 2; iters: 870\n",
      "2020-06-04 12:50:04\n",
      "val GAP 0.82712; epoch: 2; iters: 880\n",
      "2020-06-04 12:50:30\n",
      "val GAP 0.82704; epoch: 2; iters: 890\n",
      "2020-06-04 12:50:57\n",
      "val GAP 0.82679; epoch: 2; iters: 900\n",
      "2020-06-04 12:51:23\n",
      "val GAP 0.82650; epoch: 2; iters: 910\n",
      "2020-06-04 12:51:49\n",
      "val GAP 0.82672; epoch: 2; iters: 920\n",
      "2020-06-04 12:52:15\n",
      "val GAP 0.82724; epoch: 2; iters: 930\n",
      "2020-06-04 12:52:42\n",
      "val GAP 0.82843; epoch: 2; iters: 940\n",
      "2020-06-04 12:53:08\n",
      "val GAP 0.82639; epoch: 2; iters: 950\n",
      "2020-06-04 12:53:34\n",
      "val GAP 0.82848; epoch: 2; iters: 960\n",
      "2020-06-04 12:54:00\n",
      "val GAP 0.82853; epoch: 2; iters: 970\n",
      "2020-06-04 12:54:27\n",
      "val GAP 0.83053; epoch: 2; iters: 980\n",
      "2020-06-04 12:54:53\n",
      "val GAP 0.82978; epoch: 2; iters: 990\n",
      "2020-06-04 12:55:19\n",
      "val GAP 0.83061; epoch: 2; iters: 1000\n",
      "2020-06-04 12:55:45\n",
      "val GAP 0.82965; epoch: 2; iters: 1010\n",
      "2020-06-04 12:56:11\n",
      "val GAP 0.82780; epoch: 2; iters: 1020\n",
      "2020-06-04 12:56:38\n",
      "val GAP 0.82705; epoch: 2; iters: 1030\n",
      "2020-06-04 12:57:04\n",
      "val GAP 0.83050; epoch: 2; iters: 1040\n",
      "2020-06-04 12:57:30\n",
      "val GAP 0.82868; epoch: 2; iters: 1050\n",
      "2020-06-04 12:57:56\n",
      "val GAP 0.82972; epoch: 2; iters: 1060\n",
      "2020-06-04 12:58:22\n",
      "val GAP 0.83131; epoch: 2; iters: 1070\n",
      "2020-06-04 12:58:48\n",
      "val GAP 0.82516; epoch: 2; iters: 1080\n",
      "2020-06-04 12:59:14\n",
      "val GAP 0.83050; epoch: 2; iters: 1090\n",
      "2020-06-04 12:59:41\n",
      "val GAP 0.83123; epoch: 2; iters: 1100\n",
      "2020-06-04 01:00:07\n",
      "val GAP 0.83084; epoch: 2; iters: 1110\n",
      "2020-06-04 01:00:33\n",
      "val GAP 0.83029; epoch: 2; iters: 1120\n",
      "2020-06-04 01:01:01\n",
      "val GAP 0.83012; epoch: 2; iters: 1130\n",
      "2020-06-04 01:01:28\n",
      "total files in train 3844\n",
      "val GAP 0.82987; epoch: 3; iters: 1140\n",
      "2020-06-04 01:01:56\n",
      "val GAP 0.83023; epoch: 3; iters: 1150\n",
      "2020-06-04 01:02:24\n",
      "val GAP 0.82567; epoch: 3; iters: 1160\n",
      "2020-06-04 01:02:51\n",
      "val GAP 0.82995; epoch: 3; iters: 1170\n",
      "2020-06-04 01:03:19\n",
      "val GAP 0.82731; epoch: 3; iters: 1180\n",
      "2020-06-04 01:03:46\n",
      "val GAP 0.82825; epoch: 3; iters: 1190\n",
      "2020-06-04 01:04:13\n",
      "val GAP 0.82987; epoch: 3; iters: 1200\n",
      "2020-06-04 01:04:40\n",
      "val GAP 0.82965; epoch: 3; iters: 1210\n",
      "2020-06-04 01:05:07\n",
      "val GAP 0.83064; epoch: 3; iters: 1220\n",
      "2020-06-04 01:05:34\n",
      "val GAP 0.83115; epoch: 3; iters: 1230\n",
      "2020-06-04 01:06:02\n",
      "val GAP 0.82805; epoch: 3; iters: 1240\n",
      "2020-06-04 01:06:29\n",
      "val GAP 0.82981; epoch: 3; iters: 1250\n",
      "2020-06-04 01:06:56\n",
      "val GAP 0.83124; epoch: 3; iters: 1260\n",
      "2020-06-04 01:07:22\n",
      "val GAP 0.82897; epoch: 3; iters: 1270\n",
      "2020-06-04 01:07:49\n",
      "val GAP 0.82996; epoch: 3; iters: 1280\n",
      "2020-06-04 01:08:15\n",
      "val GAP 0.83027; epoch: 3; iters: 1290\n",
      "2020-06-04 01:08:42\n",
      "val GAP 0.83060; epoch: 3; iters: 1300\n",
      "2020-06-04 01:09:09\n",
      "val GAP 0.82955; epoch: 3; iters: 1310\n",
      "2020-06-04 01:09:35\n",
      "val GAP 0.83180; epoch: 3; iters: 1320\n",
      "2020-06-04 01:10:02\n",
      "val GAP 0.83128; epoch: 3; iters: 1330\n",
      "2020-06-04 01:10:29\n",
      "val GAP 0.83111; epoch: 3; iters: 1340\n",
      "2020-06-04 01:10:56\n",
      "val GAP 0.83229; epoch: 3; iters: 1350\n",
      "2020-06-04 01:11:22\n",
      "val GAP 0.83241; epoch: 3; iters: 1360\n",
      "2020-06-04 01:11:49\n",
      "val GAP 0.83281; epoch: 3; iters: 1370\n",
      "2020-06-04 01:12:16\n",
      "val GAP 0.83379; epoch: 3; iters: 1380\n",
      "2020-06-04 01:12:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val GAP 0.83301; epoch: 3; iters: 1390\n",
      "2020-06-04 01:13:10\n",
      "val GAP 0.83125; epoch: 3; iters: 1400\n",
      "2020-06-04 01:13:37\n",
      "val GAP 0.83194; epoch: 3; iters: 1410\n",
      "2020-06-04 01:14:05\n",
      "val GAP 0.83110; epoch: 3; iters: 1420\n",
      "2020-06-04 01:14:32\n",
      "val GAP 0.83209; epoch: 3; iters: 1430\n",
      "2020-06-04 01:15:00\n",
      "val GAP 0.83311; epoch: 3; iters: 1440\n",
      "2020-06-04 01:15:27\n",
      "val GAP 0.83224; epoch: 3; iters: 1450\n",
      "2020-06-04 01:15:54\n",
      "val GAP 0.83022; epoch: 3; iters: 1460\n",
      "2020-06-04 01:16:21\n",
      "val GAP 0.83209; epoch: 3; iters: 1470\n",
      "2020-06-04 01:16:48\n",
      "val GAP 0.83370; epoch: 3; iters: 1480\n",
      "2020-06-04 01:17:16\n",
      "val GAP 0.83352; epoch: 3; iters: 1490\n",
      "2020-06-04 01:17:43\n",
      "val GAP 0.83128; epoch: 3; iters: 1500\n",
      "2020-06-04 01:18:10\n",
      "val GAP 0.83417; epoch: 3; iters: 1510\n",
      "2020-06-04 01:18:38\n",
      "total files in train 3844\n",
      "val GAP 0.83182; epoch: 4; iters: 1520\n",
      "2020-06-04 01:19:07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-f827bfec3805>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_eph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf_itr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx1_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx2_trn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-f827bfec3805>\u001b[0m in \u001b[0;36mtf_itr\u001b[0;34m(tp, batch)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mlbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# yield np.array(rgb), np.array(lbs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weight file: weights/0.83417_3_1510.h5\n",
      "total files in test 3844\n",
      "10240/10240 [==============================] - 1s 86us/sample\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tf_itr(\"t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
