{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_folder = \"/media/watemerald/Seagate/data/yt8m/video/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfiles = sorted(glob.glob(os.path.join(media_folder, \"train*tfrecord\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/watemerald/Seagate/data/yt8m/video/train0000.tfrecord'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tfiles[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for example in tf.data.TFRecordDataset(t).as_numpy_iterator():\n",
    "    a.append(tf.train.Example.FromString(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b.features.feature[\"mean_rgb\"].float_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b.features.feature[\"mean_audio\"].float_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'labels', 'mean_rgb', 'mean_audio']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b.features.feature.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64_list {\n",
       "  value: 0\n",
       "  value: 1\n",
       "  value: 5\n",
       "  value: 69\n",
       "  value: 378\n",
       "  value: 597\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.features.feature['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import video_search.models.netvlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, ReLU, Softmax, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.initializers import RandomUniform, Zeros\n",
    "\n",
    "\n",
    "from video_search.utils import create_logger\n",
    "\n",
    "log = create_logger(__name__, \"file.log\")\n",
    "\n",
    "TENSORBOARD_LOG_DIR = \"logs/netvlad\"\n",
    "WEIGHTS_DIR = os.path.join(TENSORBOARD_LOG_DIR, \"weights/\")\n",
    "DATA_FILE = os.path.join(TENSORBOARD_LOG_DIR, \"data.json\")\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/antoine77340/LOUPE/blob/master/loupe.py\n",
    "# Translated into custom keras layers\n",
    "\n",
    "\n",
    "class ContextGating(Layer):\n",
    "    \"\"\"Creates a Context Gating layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Create a trainable weight variable for this layer\n",
    "        \"\"\"\n",
    "        self.gating_weights = self.add_weight(\n",
    "            name=\"kernel_W1\",\n",
    "            shape=(input_shape[-1], input_shape[-1]),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(input_shape[-1])\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.gating_biases = self.add_weight(\n",
    "            name=\"kernel_B1\",\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(input_shape[-1])\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gates = K.dot(inputs, self.gating_weights)\n",
    "        gates += self.gating_biases\n",
    "        gates = tf.sigmoid(gates)\n",
    "\n",
    "        activation = tf.multiply(inputs, gates)\n",
    "        return activation\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple(input_shape)\n",
    "\n",
    "\n",
    "class NetVLAD(Layer):\n",
    "    \"\"\"Creates a NetVLAD layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n",
    "        self.feature_size = feature_size\n",
    "        self.max_samples = max_samples\n",
    "        self.output_dim = output_dim\n",
    "        self.cluster_size = cluster_size\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Create a trainable weight variable for this layer\n",
    "        \"\"\"\n",
    "        self.cluster_weights = self.add_weight(\n",
    "            name=\"kernel_W1\",\n",
    "            shape=(self.feature_size, self.cluster_size),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(self.feature_size)\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.cluster_biases = self.add_weight(\n",
    "            name=\"kernel_B1\",\n",
    "            shape=(self.cluster_size,),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(self.feature_size)\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.cluster_weights2 = self.add_weight(\n",
    "            name=\"kernel_W2\",\n",
    "            shape=(1, self.feature_size, self.cluster_size),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(self.feature_size)\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.hidden1_weights = self.add_weight(\n",
    "            name=\"kernel_H1\",\n",
    "            shape=(self.cluster_size * self.feature_size, self.output_dim),\n",
    "            initializer=tf.random_normal_initializer(\n",
    "                stddev=1 / math.sqrt(self.cluster_size)\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, reshaped_input):\n",
    "        \"\"\"Forward pass of a NetVLAD block\n",
    "        \"\"\"\n",
    "        activation = K.dot(reshaped_input, self.cluster_weights)\n",
    "\n",
    "        activation += self.cluster_biases\n",
    "\n",
    "        activation = tf.nn.softmax(activation)\n",
    "\n",
    "        activation = tf.reshape(activation, [-1, self.max_samples, self.cluster_size])\n",
    "\n",
    "        a_sum = tf.reduce_sum(activation, -2, keepdims=True)\n",
    "\n",
    "        a = tf.multiply(a_sum, self.cluster_weights2)\n",
    "\n",
    "        activation = tf.transpose(activation, perm=[0, 2, 1])\n",
    "\n",
    "        reshaped_input = tf.reshape(\n",
    "            reshaped_input, [-1, self.max_samples, self.feature_size]\n",
    "        )\n",
    "\n",
    "        vlad = tf.matmul(activation, reshaped_input)\n",
    "        vlad = tf.transpose(vlad, perm=[0, 2, 1])\n",
    "        vlad = tf.subtract(vlad, a)\n",
    "        vlad = tf.nn.l2_normalize(vlad, 1)\n",
    "        vlad = tf.reshape(vlad, [-1, self.cluster_size * self.feature_size])\n",
    "        vlad = tf.nn.l2_normalize(vlad, 1)\n",
    "        vlad = K.dot(vlad, self.hidden1_weights)\n",
    "\n",
    "        return vlad\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.output_dim])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"feature_size\": self.feature_size,\n",
    "            \"max_samples\": self.max_samples,\n",
    "            \"cluster_size\": self.cluster_size,\n",
    "            \"output_dim\": self.output_dim,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class MoE(Layer):\n",
    "    \"\"\"Mixture-of-experts layer.\n",
    "    Implements: y = sum_{k=1}^K g(v_k * x) f(W_k * x)\n",
    "\n",
    "    Params:\n",
    "    units: the number of hidden units\n",
    "    n_experts: the number of experts\n",
    "    expert_activation: ReLU\n",
    "    gating_activation: Softmax\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units: int, n_experts: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.n_experts = n_experts\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        expert_init_lim = np.sqrt(3.0 / (max(1.0, float(input_dim + self.units) / 2)))\n",
    "        gating_init_lim = np.sqrt(3.0 / (max(1.0, float(input_dim + 1) / 2)))\n",
    "\n",
    "        self.expert_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.units, self.n_experts),\n",
    "            initializer=RandomUniform(minval=-expert_init_lim, maxval=expert_init_lim),\n",
    "            name=\"expert_kernel\",\n",
    "        )\n",
    "\n",
    "        self.gating_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.n_experts),\n",
    "            initializer=RandomUniform(minval=-gating_init_lim, maxval=gating_init_lim),\n",
    "            name=\"gating_kernel\",\n",
    "        )\n",
    "\n",
    "        self.expert_bias = self.add_weight(\n",
    "            shape=(self.units, self.n_experts), initializer=Zeros, name=\"expert_bias\"\n",
    "        )\n",
    "\n",
    "        self.gating_bias = self.add_weight(\n",
    "            shape=(self.n_experts,), initializer=Zeros, name=\"gating_bias\"\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        expert_outputs = tf.tensordot(inputs, self.expert_kernel, axes=1)\n",
    "        expert_outputs = K.bias_add(expert_outputs, self.expert_bias)\n",
    "        expert_outputs = ReLU()(expert_outputs)\n",
    "\n",
    "        gating_outputs = K.dot(inputs, self.gating_kernel)\n",
    "        gating_outputs = K.bias_add(gating_outputs, self.gating_bias)\n",
    "        gating_outputs = Softmax()(gating_outputs)\n",
    "\n",
    "        gating_outputs = K.sum(\n",
    "            expert_outputs\n",
    "            * K.repeat_elements(\n",
    "                K.expand_dims(gating_outputs, axis=1), self.units, axis=1\n",
    "            ),\n",
    "            axis=2,\n",
    "        )\n",
    "\n",
    "        output = Softmax()(gating_outputs)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"units\": self.units, \"n_experts\": self.n_experts}\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_search.models.shared import NeuralNet, AUDIO_DATA, VIDEO_DATA, OUTPUT_CLASSES\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "class NetVLADModel(NeuralNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(TENSORBOARD_LOG_DIR, WEIGHTS_DIR, DATA_FILE, log)\n",
    "\n",
    "    def build_model(\n",
    "        self, netvlad_cluster_size: int = 256, n_experts: int = 2, **kwargs\n",
    "    ) -> Model:\n",
    "        \"\"\"Builds a gated NetVLAD classification model\n",
    "\n",
    "        Reference:\n",
    "        Miech, Antoine, Ivan Laptev, and Josef Sivic.\n",
    "        \"Learnable pooling with context gating for video classification.\"\n",
    "        arXiv preprint arXiv:1706.06905 (2017).\n",
    "        \"\"\"\n",
    "        in1 = Input((AUDIO_DATA,), name=\"x1\")\n",
    "        x1 = NetVLAD(AUDIO_DATA, batch_size, netvlad_cluster_size, AUDIO_DATA)(in1)\n",
    "\n",
    "        in2 = Input((VIDEO_DATA,), name=\"x2\")\n",
    "        x2 = NetVLAD(VIDEO_DATA, batch_size, netvlad_cluster_size, VIDEO_DATA)(in2)\n",
    "\n",
    "        x = concatenate([x1, x2], 1)\n",
    "        x = ContextGating()(x)\n",
    "\n",
    "        x = MoE(OUTPUT_CLASSES, n_experts)(x)\n",
    "\n",
    "        out = ContextGating(name=\"output\")(x)\n",
    "\n",
    "        model = Model([in1, in2], out)\n",
    "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = NetVLADModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = a.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, aud, rgb, lbs = [], [], [], []\n",
    "for example in tf.data.TFRecordDataset(t).as_numpy_iterator():\n",
    "    # Parse a single record from the dataset and extract all its values\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "    ids.append(\n",
    "        tf_example.features.feature[\"id\"]\n",
    "        .bytes_list.value[0]\n",
    "        .decode(encoding=\"UTF-8\")\n",
    "    )\n",
    "    rgb.append(\n",
    "        np.array(tf_example.features.feature[\"mean_rgb\"].float_list.value)\n",
    "    )\n",
    "    aud.append(\n",
    "        np.array(tf_example.features.feature[\"mean_audio\"].float_list.value)\n",
    "    )\n",
    "\n",
    "    # Convert a list of labels into a 1D vector where all the labels are marked as 1\n",
    "    yss = np.array(tf_example.features.feature[\"labels\"].int64_list.value)\n",
    "\n",
    "    out = np.zeros(OUTPUT_CLASSES).astype(np.int8)\n",
    "    for y in yss:\n",
    "        out[y] = 1\n",
    "\n",
    "    lbs.append(out)\n",
    "    \n",
    "    if len(ids) > 256:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NetVLADModel().build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# loss = math.inf\n",
    "\n",
    "# while loss > 0.0001:\n",
    "#     aud = np.array(aud)\n",
    "#     rgb = np.array(rgb)\n",
    "#     lbs = np.array(lbs)\n",
    "#     loss = m.train_on_batch(\n",
    "#         {\"x1\": aud, \"x2\": rgb}, {\"output\": lbs}\n",
    "#     )\n",
    "#     print(f\"loss: {loss} \\t learning_rate: {m.optimizer.learning_rate.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = np.array(aud)\n",
    "rgb = np.array(rgb)\n",
    "lbs = np.array(lbs)\n",
    "\n",
    "loss = m.train_on_batch(\n",
    "        {\"x1\": aud, \"x2\": rgb}, {\"output\": lbs}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = m.predict({\"x1\": aud, \"x2\": rgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49833632"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 4716)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4088859283821408"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from video_search.models.shared import mean_ap\n",
    "\n",
    "mean_ap(p, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
